%Version 2.1 April 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove �Numbered� in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst, sn-mathphys.bst. %  
 
%%\documentclass[sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
\documentclass[sn-mathphys,Numbered]{sn-jnl}% Math and Physical Sciences Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver,Numbered]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%

\usepackage{graphicx}
\usepackage{subcaption}
%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%\jyear{2021}%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[Article Title]{Breast Cancer Image Classification:  Impact of Limited Data Examples}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate} 
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*[1]{\fnm{Michael} \sur{Brewer}}\email{mlbrewer@ualr.edu}

\affil*[1]{\orgdiv{Computer and Information Sciences}, \orgname{University of Arkansas, Little Rock}, \state{Arkansas}, \country{USA} }

%%==================================%%
%% sample for unstructured abstract %%
%%==================================%%

\abstract{In this paper we study classifying ultrasound images of breast tissues to determine if the image contains a tumor and, if so, whether that tumor is benign or malignant.  We use this classification problem and to study the effect of a small training dataset to devise strategies for handling other image classifications for more rare conditions.  In addition, we use Explainable AI approaches to observe what areas of the image are positively or negatively impacting the classification prediction and, correspondingly, the accuracy of the prediction.}

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

\keywords{Breast Cancer; CNN; Data Augmentation; Explainable AI}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Introduction}\label{sec_intro}
The ability to correctly interpret medical images is critical in diagnosis and prognosis in many medical disciplines, and Convolutional Neural Networks (CNNs) have helped and continue to help revolutionalize the field \cite{2022_survey}.  Researchers have devised and trained CNNs to detect Breast Cancer ultrasound images mammograms.  For example, see \cite{AREVALO2016248}.  As one of the most common cancers in the world, Breast Cancer is widely studied, and a variety of datasets exist in the public domain for trianing models on this problem.  Other, more rare disease, have much more limited datasets world-wide, whether in the public domain or not.  Childhood cancers, for example, are much more rare than adult cancers.  Figure \ref{fig:CDC_Rates} shows the number of cancer diagnoses by age group in the US in 2019 \cite{cdc}.  Note the plot is on a log scale because of the orders of magnitude differences between childhood and adult cancers, particularly for adults over 40.  Due to this discripency, datasets for childhood cancers in general, and particularly rare childhood cancers can be prohibitively difficult to obtain.  


\begin{figure}[!htbp]
    \centering

    \includegraphics[width=\textwidth]{img/CDC_rates.png}

    \caption{Rates of cancer diagnosis by age group per 10,000 individuals \cite{cdc}}
    \label{fig:CDC_Rates}
\end{figure}


Because of the availabity of breast cancer image data, in this study we use that as a proxy for other rare diseases, specifically to study how the quantity of available training samples impacts our model.  We note there are concerns with this approach.  It is not immediately evident this breast cancer study will fairly mimick the rare diseases for which it serves as proxy.  The base models used for training may have already been exposed to Breast Cancer images, for example, or the more rare cancers could have entirely different features or heterogenaties.   However, with the breast dataset, we can restrict the data of an individual class artificially, and therefore see how the model is impacted by various levels of that restriction.


\section{Training Data and Augmentation}\label{sec_data}
The data used for this project is available at Kaggle https://www.kaggle.com/datasets/aryashah2k/breast-ultrasound-images-dataset .  This dataset contains 780 ultrasound images from 600 patients.  These images are classified as “normal”, “benign”, or “malignant” based on a professional classification of the existence and type of breast cancer tumors.  See \cite{breast_data}.  A sample from the maligannt class of this dataset is shown in Figure \ref{fig:example_mal}.  The image classifications are imbalanced with the distribution given in Table \ref{dataclasses}.  In this study, we perform a train-test split on the data, before any augmentation, using 80\% of the data for training and 20\% for testing.  We do not reserve a portion for validation, instead using the test data set as our final evaluation dataset.  The number of samples within each class for training and testing are also shown in  Table \ref{dataclasses}.

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{img/mal_192.png}
    \caption{Randomly selected image from the malignant classification group.}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{img/mal_192_mask.png}
    \caption{Associated mask corresponding to the malignant tumor.}
  \end{subfigure}
  \caption{Comparison of images and masks.}
   \label{fig:example_mal}
\end{figure}

\begin{table}[h]
\caption{The number of samples in each classification in the original dataset, the training set, and the test set.  The last column shows what percentage of the full class sample count is represented by the test set.}\label{dataclasses}
\begin{tabular}{@{}lllll@{}}%
\toprule
Class & Full  & Training & Test & Test Percentage of Full\\
\midrule
normal & 133    & 104   & 29 & 21.8\% \\
benign & 437    & 353  & 84 & 19.2\%  \\
malignant & 210    &   167 & 43  & 20.5\%  \\
\botrule
\end{tabular}
\end{table}
In this work, we consider multiple types of data augmentation.  

\subsection{Class Balancing}
After perfroming the train-test split on our original dataset, the training dataset is not balanced.  
As explained by Huang {\it et al.} \cite{Huang_2016_CVPR}, there are several techniques available to deal with this imbalance.  Popular method categories include oversampling, undersampling, and cost-sensitive learning techniques.  Because our dataset is limited in size, we utilize oversampling with replacement to balance our dataset \cite{Huang_2016_CVPR}, augmenting the classes with fewer samples \cite{tensorflow-imagedatagenerator} by varying the existing examples using techniques like scaling and rotation.  This augmentation is used to bring all classes up to 353 samples to match the largest training class, `benign'.  This augmentation is accomplished by using an ImageDataGenerator \cite{tensorflow-imagedatagenerator} to iterate over the input folders to generate the additional images and generate variations.  In later sections, this technique is labeled ``balancing".  The settings for this are given below:
\lstset{texcl=true,basicstyle=\small\sf,commentstyle=\small\rm,mathescape=true,escapeinside={(*}{*)}}
\begin{lstlisting}

    image_generator = ImageDataGenerator(rescale=rescale,
                                         zoom_range=.2,
                                         horizontal_flip=True,
                                         rotation_range=40,
                                         width_shift_range=0.05,
                                         height_shift_range=.05,
                                         brightness_range=[0.9, 1.1])
    image_generator.flow_from_dataframe(given_df,
                                         target_size=image_size,
                                         batch_size=batch_size,
                                         class_mode='categorical',
                                         shuffle=True,
                                         seed=42)
\end{lstlisting}

\subsection{Augmentation to Expand Training Set Prior to Training}
Using the same technique as above, we can utilize the same ImageDataGenerator to generate additional samples of all classes.  We utilize this approach to, for example, generate additional images beyond the number needed balance.  Note that both of these method which augment the data prior to training will increase the epoch size during training.   In later sections, this technique is labeled ``expansion augmentation", and the number of images reported is how many additional images were added to each class beyond the 353 used to balance. 

\subsection{Continuous Augmentation to Expand Diversity during Training}
We can additionally expand the sample diversity during training.  Keras provides CNN layers which can, during training, modify the input image with techniques like rotation or contrast adjustment.  However, adding these layers adds complexity relative to continue relying on the ImageDataGenerator to provide additional diversity.  Therefore, for training-time augmentation, we rely on an ImageDataGenerator. In later sections, this technique is labeled ``continuous augmentation".  With this continuous augmentation, images will be modified differently for each epoch.  That is, expansion augmentation will generate large image sets for a single epoch, and continuous augmentation will add diversity each iteration through an epoch.  

\section{Model}\label{sec_model}
The base model, defined in code as base\_model, was constructed from EfficientNetB2 \cite{effnet}.  This base model was then enhanced with additional layers to make the model appropriate for our Breast Cancer classification use-case.  The model is shown below
\lstset{texcl=true,basicstyle=\small\sf,commentstyle=\small\rm,mathescape=true,escapeinside={(*}{*)}}
\begin{lstlisting}

  model = tf.keras.Sequential([
    resize_and_rescale,
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.BatchNormalization(),
    layers.Dropout(top_dropout_rate, name="top_dropout"),
    layers.Dense(num_classes, activation='softmax')
  ])


\end{lstlisting}

The first layer simply resizes input images to the expected size (260,260) and converts the anticipated 8-bit images range to [0,1].  Then, after the base\_model has been included, additional layers are included to perform 
\begin{itemize}
\item global average pooling to downsample,
\item batch normalization to improve convergence,
\item dropput at a rate of .2, and finally
\item classification of the three classes using softmax.
\end{itemize}

All training procedures use a batch size of 32.  The learning rate was on a schedule that moved from .0001 to .00001 at the 20\textsuperscript{th} epoch, if that epoch was reached.  Training was terminated if the loss function, evaluated on the test set, failed to improve on the best value in 3 consecutive epochs.  All training was done using Google Colaboratory, a web-based development environment.  See \cite{colab}.  Training leveraged a T4 GPU.

\section{Training Results}\label{sectraining}
\subsection{Augmentation Results}\label{sectraining_augmentation}
To evaluate the benefits of various augmentation techiques, the model was trained without any initial augmentation, with a balanced dataset, and then with an additional 2,000 sames generated for each class.  Each of these variations were performed with and without continuous data augmentation during the traing itself.  The confusion matrix results are shown in figure \ref{fig:2x3_original}.   For these results, we additionally show the precision, recall, and F1 score for the malignant class.  The focus on the malignant class is due to
\begin{itemize}
\item it being particularly important to have good recall on the malignant class due to the real-world implications of failing to recognize a malignant tumor and
\item our use later of this class to mimic very limited data representation for certain classes.
\end{itemize}
The results are summarized in Table \ref{dataaccuracies}.

When training with the small, original dataset or with that dataset augmented to be balanced, we see significant improvement, in both accuracy and `malignant' class recall, by using the continuous augmentation technique.  This trend is not maintained with the larger, augmented dataset.  With the larger, augmented dataset we see a small reduction in accuracy using continuous augmentation.   

Also of note, counter-intuitively, the balanced dataset without continuous augmentation classifies most samples as `benign', the most prevalent of the sample classes in the original dataset.  Further work would be needed to explain this adequately.  It could imply an instability in our model such that the optimization is finding a degenerate solution.  It could also suggest that the augmented data is not adequately representing the original data.  However, without continuous augmentation, starting with the smaller datasets produces very poor (unusable) trained models regardless of balancing.

\begin{figure}[!htbp]
    \centering

    \includegraphics[width=\textwidth]{summary/2x3_original.png}

    \caption{A set of confusion matrices based on various hyperparameters.  On the left are confusion matrices from training without continuous augmentation, while on he right are confusion matrices with conintuous augmentation.  The first row used the original dataset without any balancing.  The second row used a balanced dataset.  The third row augments the balanced dataset by generating an addition 2,000 samples per class.}
    \label{fig:2x3_original}
\end{figure}



\begin{table}[h]
\caption{Summary of the accuracies achieved on the test sets for varioius training approaches.}\label{dataaccuraces}
\begin{tabular}{@{}lllll@{}}%
\toprule
Continuous Aug. & Balanced & \# for Expansion Aug.  & Accuracy & `malignant' Recall\\
\midrule
False & False & 0 & 56\% & .40 \\
True & False & 0 & 76\% & .70 \\
False & True & 0 & 55\% & .12 \\
True & True & 0 & 85\% & .84 \\
False & True & 2,000 & 91\% & .91 \\
True & True & 2,000 & 87\% & .86 \\
\botrule
\end{tabular}
\end{table}



\subsection{Mimicking Reduced Class Representations}\label{sectraining_reductions}
To evaluate the effect of limited class represetnation in the dataset available for training, we artificially reduce the `malignant' class after performing the train/test split.  Note that this is not entirely representative of the real-world case.  Our test set still contains the 20\% representation based on the original dataset.  This is done to preserve consistency among all the runs of having the exact same test set.  Further comparisons could be done by reducing the datsaet prior to train/test in future work.

\begin{figure}[!htbp]
    \centering

    \resizebox{!}{0.8\textheight}{\includegraphics[width=\textwidth]{summary/2x5_reductions.png}}

    \caption{A set of confusion matrices based the percentage of training `malignant' class examples which were removed before augmentation and training.  On the left are confusion matrices from training without continuous augmentation, while on he right are confusion matrices with continuous augmentation.  The first row represents no reduction and is equivalent to the last rown seen in Figure \ref{fig:2x3_original}.  The second through fifth represent reductions in the `malignant' training set by 50\%, 65\%, 80\%, and 95\%, respectively.}
    \label{fig:2x5_reductions}
\end{figure}

\begin{table}[h]
\caption{Summary of the accuracies achieved on the test sets for varioius training approaches.}\label{datareductions}
\begin{tabular}{@{}lllll@{}}%
\toprule
Continuous Aug. & \# for Expansion Aug.  & \% Reduced&  Accuracy & `malignant' Recall\\
\midrule
False & 2,000 & 0\%& 91\% & .91 \\
True & 2,000 & 0\%& 87\% & .86 \\
False & 2,000 & 50\%& 89\% & .81 \\
True & 2,000 & 50\%& 90\% & .86 \\
False & 2,000 & 65\%& 75\% & .42 \\
True & 2,000 &65\%& 85\% & .63 \\
False & 2,000 & 80\%& 77\% & .42 \\
True & 2,000 & 80\%& 85\% & .60 \\
False & 2,000 & 95\%& 54\% & .00 \\
True & 2,000 &95\%& 65\% & .12 \\
\botrule
\end{tabular}
\end{table}

These results may be more easily observed in Figure \ref{fig:reduction_performance} where four metrics are plotted as a function of the reduction rate.  The dashed line indicates the model in which continuous augmentation was not used, and the solid line represents the model in which it was used.  With more than 50 percent reduction we see significant drop-off in the model performance.  (Note that while the precision for the `malignant' class remains high for many of these models, the more critical measures of recall and F1 decline drastically.) 

\begin{figure}[!htbp]
    \centering

    \includegraphics[width=\textwidth]{summary/reduction_performance.png}

    \caption{Various model performance as a function of reduction rate where reduction rate defines how much of the `malignant' class's training set is hidden before augmentation and training.}
    \label{fig:reduction_performance}
\end{figure}


\section{Explainability}\label{sec_explain}


\begin{figure}[!htbp]
    \centering

    \includegraphics[width=\textwidth]{summary/proportion_mal_and_benign.png}

    \caption{Each plot shows the proportion of pixels contributing to a prediction.  The x-axis shows the proportion inside the tumor mask positively contributing to the prediction, while the y-axis shows the proportion of pixels outside tumor mask positively contributing.  On the left chart, we consider contriubtions towards the correct label, and on the right, we consider contributions towards the wrong label.}
    \label{fig:proportion}
\end{figure}


\section{Conclusions}\label{sec_conclusion}

\section{Future Work}\label{sec_future}

In the present work, the LIME model was used to generate explanatory masks.  However, other techniques like SHAP or Layer-wise Relevance BackPropagation (LRP) might provide more informative explanations \cite{SALEEM2022165}.  Specifically, having techniques to provide a quantative value of the impact of individual pixels would be more informative.  We plan to use such values to determine the sum of pixels inside the masked areas versus outside.  Similarly, one would reasonably expect the pixels near the mask to be valuable to the classification, and therefore we plan to weight pixels by proximity to the masks for analysis, not just inside or outside the mask, as was done in this study.

%\begin{appendices}

%\section{Section title of first appendix}\label{secA1}



%%=============================================%%
%% For submissions to Nature Portfolio Journals %%
%% please use the heading ``Extended Data''.   %%
%%=============================================%%

%%=============================================================%%
%% Sample for another appendix section			       %%
%%=============================================================%%

%% \section{Example of another appendix section}\label{secA2}%
%% Appendices may be used for helpful, supporting or essential material that would otherwise 
%% clutter, break up or be distracting to the text. Appendices can consist of sections, figures, 
%% tables and equations etc.

%\end{appendices}

%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%

\bibliography{sn-bibliography}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl


\end{document}
